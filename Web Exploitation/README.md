where are the robots:  
        "robots" in a web exploitation test reminds me of robots.txt: The text file that tells search engines which parts of the website is fair game. So,   
        - Access robots.txt by {link}/robots.txt  
        - Given: Disallow: (something).html  
        - GOTO {link}/(something).html and take the flag  

Insp3ct0r:  
        Challenge repeatedly references html, css and js. Hence, visit the html, css and js files of given website afnd look at the comments.  
 
